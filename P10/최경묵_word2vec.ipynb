{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "here I implement word2vec with very simple example using tensorflow  \n",
    "word2vec is vector representation for words with similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "we will use only 10 sentences to create word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words\n",
    "In order for efficiency of creating word vector, we will remove commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(corpus):\n",
    "    stop_words = ['is', 'a', 'will', 'be']\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we have word set by which we will have word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy',\n",
       " 'girl',\n",
       " 'king',\n",
       " 'man',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation\n",
    "we will generate label for each word using skip gram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : pretty : <enumerate object at 0x7ffb4832ea68>\n",
      "1 : young : <enumerate object at 0x7ffb4832ea68>\n",
      "2 : strong : <enumerate object at 0x7ffb4832ea68>\n",
      "3 : man : <enumerate object at 0x7ffb4832ea68>\n",
      "4 : princess : <enumerate object at 0x7ffb4832ea68>\n",
      "5 : wise : <enumerate object at 0x7ffb4832ea68>\n",
      "6 : boy : <enumerate object at 0x7ffb4832ea68>\n",
      "7 : woman : <enumerate object at 0x7ffb4832ea68>\n",
      "8 : queen : <enumerate object at 0x7ffb4832ea68>\n",
      "9 : girl : <enumerate object at 0x7ffb4832ea68>\n",
      "10 : king : <enumerate object at 0x7ffb4832ea68>\n",
      "11 : prince : <enumerate object at 0x7ffb4832ea68>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=enumerate(words)\n",
    "for i, key in x:\n",
    "    print(i, \":\", key, \":\", x)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "    \n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king strong man\n",
      "queen wise woman\n",
      "boy young man\n",
      "girl young woman\n",
      "prince young king\n",
      "princess young queen\n",
      "man strong\n",
      "woman pretty\n",
      "prince boy king\n",
      "princess girl queen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for text in corpus:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strong</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>queen</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queen</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wise</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>woman</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>woman</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>boy</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>boy</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>young</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>young</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>man</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>man</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>girl</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>girl</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input   label\n",
       "0     king  strong\n",
       "1     king     man\n",
       "2   strong    king\n",
       "3   strong     man\n",
       "4      man    king\n",
       "5      man  strong\n",
       "6    queen    wise\n",
       "7    queen   woman\n",
       "8     wise   queen\n",
       "9     wise   woman\n",
       "10   woman   queen\n",
       "11   woman    wise\n",
       "12     boy   young\n",
       "13     boy     man\n",
       "14   young     boy\n",
       "15   young     man\n",
       "16     man     boy\n",
       "17     man   young\n",
       "18    girl   young\n",
       "19    girl   woman"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns = ['input', 'label'])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretty': 0,\n",
       " 'young': 1,\n",
       " 'strong': 2,\n",
       " 'man': 3,\n",
       " 'princess': 4,\n",
       " 'wise': 5,\n",
       " 'boy': 6,\n",
       " 'woman': 7,\n",
       " 'queen': 8,\n",
       " 'girl': 9,\n",
       " 'king': 10,\n",
       " 'prince': 11}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "# making placeholders for X_train and Y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 \n",
    "\n",
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "# output layer\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "# training operation\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  3.7276945\n",
      "iteration 3000 loss is :  1.8803385\n",
      "iteration 6000 loss is :  1.7948353\n",
      "iteration 9000 loss is :  1.7703426\n",
      "iteration 12000 loss is :  1.7555199\n",
      "iteration 15000 loss is :  1.7452319\n",
      "iteration 18000 loss is :  1.7375755\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteration = 20000\n",
    "for i in range(iteration):\n",
    "    # input is X_train which is one hot encoded word\n",
    "    # label is Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0864182   3.1003485 ]\n",
      " [ 0.0571052  -0.07725429]\n",
      " [-3.7159438  -5.029915  ]\n",
      " [-0.8174745  -0.4246453 ]\n",
      " [ 5.2274914  -2.3719833 ]\n",
      " [ 3.0854957   0.41419354]\n",
      " [-0.7902232  -1.5265468 ]\n",
      " [ 1.0323662  -0.43926352]\n",
      " [ 1.6504235  -0.8369054 ]\n",
      " [ 3.2807727  -1.4949929 ]\n",
      " [-0.5387617  -0.5222064 ]\n",
      " [-1.6487112  -1.7257406 ]]\n"
     ]
    }
   ],
   "source": [
    "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretty</td>\n",
       "      <td>2.086418</td>\n",
       "      <td>3.100348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>young</td>\n",
       "      <td>0.057105</td>\n",
       "      <td>-0.077254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>-3.715944</td>\n",
       "      <td>-5.029915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man</td>\n",
       "      <td>-0.817474</td>\n",
       "      <td>-0.424645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>princess</td>\n",
       "      <td>5.227491</td>\n",
       "      <td>-2.371983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wise</td>\n",
       "      <td>3.085496</td>\n",
       "      <td>0.414194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>boy</td>\n",
       "      <td>-0.790223</td>\n",
       "      <td>-1.526547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>woman</td>\n",
       "      <td>1.032366</td>\n",
       "      <td>-0.439264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>queen</td>\n",
       "      <td>1.650424</td>\n",
       "      <td>-0.836905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>girl</td>\n",
       "      <td>3.280773</td>\n",
       "      <td>-1.494993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>king</td>\n",
       "      <td>-0.538762</td>\n",
       "      <td>-0.522206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>prince</td>\n",
       "      <td>-1.648711</td>\n",
       "      <td>-1.725741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word        x1        x2\n",
       "0     pretty  2.086418  3.100348\n",
       "1      young  0.057105 -0.077254\n",
       "2     strong -3.715944 -5.029915\n",
       "3        man -0.817474 -0.424645\n",
       "4   princess  5.227491 -2.371983\n",
       "5       wise  3.085496  0.414194\n",
       "6        boy -0.790223 -1.526547\n",
       "7      woman  1.032366 -0.439264\n",
       "8      queen  1.650424 -0.836905\n",
       "9       girl  3.280773 -1.494993\n",
       "10      king -0.538762 -0.522206\n",
       "11    prince -1.648711 -1.725741"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in 2d chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAH1lJREFUeJzt3Xl01dW99/H3lzBVQLQXaqEMofeBAplPgkJJmCfL1KSAcMHFoBehtVWfgpTrrYDF1VZQq7ctXq0CVYqIKG2VWoZiITVXScJYRq0xVew1PKgNg0DC9/kjkKUIBDgT4fd5rZW1POf8zt7fndaPO79hb3N3REQkOOrEuwAREYktBb+ISMAo+EVEAkbBLyISMAp+EZGAUfCLiASMgl9EJGAU/CIiAROx4DezBDPbbGYvRapNERGJvLoRbOsOYBdwdU0HNmvWzBMTEyPYtYjIla+oqOiAuzcPt52IBL+ZtQIGA/cD/7em4xMTEyksLIxE1yIigWFm70SinUid6vkZcDdwMkLtiYhIlIQd/GY2BPjA3YtqOG6ymRWaWWFZWVm43YqIyCWKxIy/OzDMzEqAZ4E+ZvbMmQe5++PunuXuWc2bh32KSkRELlHYwe/uM929lbsnAqOBP7n7uLArExGRqNB9/CIiARPJ2zlx91eBVyPZpoiIRJZm/CIiAaPgFxEJGAW/iEjAKPhFRAJGwS8iEjAKfhGRgFHwiwTQypUr2blzZ/XrRYsWsX///jhWJLGk4Be5QlVWVp7zMwV/sCn4RWqhkpISOnbsyPjx40lNTWXEiBEcOXKExMRE7rvvPrKzs1m+fDlvvfUWgwYNIjMzk5ycHHbv3s1rr73G7373O6ZPn056ejo//elPKSwsZOzYsaSnp/Pyyy+Tm5tb3deaNWvIy8uL42gl0iL65K6IxM6ePXt48skn6d69O5MmTeKXv/wlAA0bNiQ/Px+Avn378thjj9G+fXtef/11vv3tb/OnP/2JYcOGMWTIEEaMGAHAH/7wB+bPn09WVhbuzve//33Kyspo3rw5CxcuZOLEiXEbp0Segl+klmrdujXdu3cHYNy4cTz66KMA3HTTTQAcOnSI1157jZEjR1Z/59ixYzW2a2bcfPPNPPPMM0ycOJGCggJ+/etfR2EEEi8KfpFayszO+rpRo0YAnDx5kmuuuYYtW7ZcdNsTJ05k6NChNGzYkJEjR1K3rqLiSqJz/CK1VGlpKQUFBQAsXbqU7Ozsz3x+9dVX065dO5YvXw6Au7N161YAmjRpQnl5efWxZ75u2bIlLVu2ZO7cuUyYMCHKI5FYU/CL1FKdOnVi8eLFpKamcvDgQaZOnfq5Y5YsWcKTTz5JWloaSUlJ/Pa3vwVg9OjRzJs3j4yMDN566y0mTJjAlClTSE9P5+jRowCMHTuW1q1b07lz55iOS6LP3D3mnWZlZbk2Wxe5dCUlJQwZMoQdO3ZErY/bb7+djIwMbrnllqj1IRfHzIrcPSvcdnTiTkQ+JzMzk0aNGvHggw/GuxSJAgW/SC2UmJgY1dl+UVFR1NqW+NM5fhGRgFHwi4gEjIJfRCRgFPwiIgGj4BcRCRgFv4hIwCj4RUQCRsEvIhIwCn4RkYBR8IuIBIyCX0QkYBT8IiIBo+AXEQkYBb+ISMAo+EVEAkbBLyISMAp+EZGACTv4zay1ma03s11m9lczuyMShYmISHREYuvFCuD77l5sZk2AIjNb4+47I9C2iIhEWNgzfnd/392LT/1zObAL+Eq47YqISHRE9By/mSUCGcDrZ/lsspkVmllhWVlZJLsVEZGLELHgN7PGwArgTnf/55mfu/vj7p7l7lnNmzePVLciInKRIhL8ZlaPqtBf4u4vRKJNERGJjkjc1WPAk8Aud38o/JJERCSaIjHj7w7cDPQxsy2nfr4RgXZFRCQKwr6d093zAYtALSIiEgN6cldEJGAU/CIiAaPgFxEJGAW/iEjAKPhFRAJGwS8iEjAKfhGRgFHwi4gEjIJfRCRgFPwiIgGj4BcRCRgFv4hIwCj4RUQCRsEvIhIwCn4RkYBR8IuIBIyCX0QkYBT8IiIBo+AXEQkYBb+ISMAo+EVEAkbBLyIR841vfIOPPvoo3mVIDerGuwARuXKsWrUq3iXIBdCMX0Qu2AMPPMCjjz4KwF133UWfPn0AWLduHePGjSMxMZEDBw5w+PBhBg8eTFpaGsnJySxbtgyAoqIievbsSWZmJgMHDuT999+P21iCTMEvIhesR48ebNy4EYDCwkIOHTrEiRMnyM/PJycnp/q4V155hZYtW7J161Z27NjBoEGDOHHiBN/97nd5/vnnKSoqYtKkSdxzzz3xGkqgKfhF5IJlZmZSVFREeXk5DRo0oFu3bhQWFrJx48bPBH9KSgpr165lxowZbNy4kaZNm7Jnzx527NhB//79SU9PZ+7cubz77rtxHE1w6Ry/iFywevXqkZiYyMKFC/n6179Oamoq69ev56233qJTp07Vx3Xo0IGioiJWrVrFzJkzGTBgALm5uSQlJVFQUBDHEQhoxi8iF6lHjx7Mnz+fHj16kJOTw2OPPUZ6ejpmVn3M/v37ueqqqxg3bhzTpk2juLiYr33ta5SVlVUH/4kTJ/jrX/8ar2EEmmb8InJRcnJyuP/+++nWrRuNGjWiYcOGnznNA7B9+3amT59OnTp1qFevHgsWLKB+/fo8//zzfO973+Pjjz+moqKCO++8k6SkpDiNJLjM3WPeaVZWlhcWFsa8XxGR2szMitw9K9x2dKpHRCRgFPwiIgGj4BcRCRgFv9RaP/zhD3nkkUeqX99zzz088sgjTJ8+neTkZFJSUqqfGH311VcZMmRI9bG33347ixYtAiAxMZFZs2YRCoVISUlh9+7dAJSVldG/f39CoRC33XYbbdu25cCBA7EboEiURCT4zWyQme0xszfN7AeRaFOkJrfccguLFy8G4OTJkzz77LO0atWKLVu2sHXrVtauXcv06dMvaFmAZs2aUVxczNSpU5k/fz4Ac+bMoU+fPhQXF5Obm0tpaWlUxyMSK2EHv5klAL8AbgQ6A2PMrHO47YrUJDExkX/5l39h8+bNrF69moyMDPLz8xkzZgwJCQlcd9119OzZk02bNtXYVl5eHlD1ZGpJSQkA+fn5jB49GoBBgwZx7bXXRm0sIrEUiRn/9cCb7v43dz8OPAsMj0C7IjW69dZbWbRoEQsXLmTSpEmc6/bkunXrcvLkyerXn3zyyWc+b9CgAQAJCQlUVFQAnLMtkdouEsH/FeDvn3r97qn3PsPMJptZoZkVlpWVRaBbEcjNzeWVV15h06ZNDBw4kB49erBs2TIqKyspKytjw4YNXH/99bRt25adO3dy7NgxPv74Y9atW1dj29nZ2Tz33HMArF69mg8//DDawxGJiUg8uWtnee9zUyV3fxx4HKoe4IpAvyLUr1+f3r17c80115CQkEBubi4FBQWkpaVhZjzwwAN8+ctfBmDUqFGkpqbSvn17MjIyamx71qxZjBkzhmXLltGzZ09atGhBkyZNoj0kkagL+8ldM+sGzHb3gadezwRw9x+f6zt6clci5eTJk4RCIZYvX0779u0j2vaxY8dISEigbt26FBQUMHXqVLZs2RLRPkQuRqSe3I3EjH8T0N7M2gHvAaOBf4tAuyLntXPnToYMGUJubm7EQx+gtLSUUaNGcfLkSerXr88TTzwR8T5E4iHsc/zuXgHcDvwR2AU85+5aci/ASkpK6NixI7feeivJycmMHTuWtWvX0r17d9q3b88bb7zBypUrueqqq8jIyODrX/86e/bsobCwkP79+5OXl8egQYNo3749d9999zn76dy5M3/729948MEHozKO9u3bs3nzZrZu3cqmTZvo0qULUPMuVEuXLiUlJYXk5GRmzJhR3V7jxo2ZMWMGmZmZ9OvXjzfeeINevXrx1a9+ld/97nfVv7ucnBxCoRChUIjXXnsNqHoOoVevXowYMYKOHTsyduxYXXyWS+fuMf/JzMx0uXK9/fbbnpCQ4Nu2bfPKykoPhUI+ceJEP3nypK9cudKHDx/u27Zt86SkJHd3X7Nmjefl5bm7+8KFC71du3b+0Ucf+dGjR71NmzZeWloaz+F8TkFBgY8YMcLd3bOzs71Lly5+/Phxnz17ts+ePdtbt27tH3zwgZ84ccJ79+7tL774oru7A75q1Sp3d//mN7/p/fv39+PHj/uWLVs8LS3N3d0PHz7sR48edXf3vXv3+ul/V9avX+9XX321//3vf/fKykrv2rWrb9y4MdZDlzgDCj0CGaxlmSUq2rVrR0pKCgBJSUn07dsXMyMlJYWSkhLKy8spLS0lOTmZEydO8M477zBv3jyWLFlC3759efjhhyktLaW8vJwbbriBH/zgB3zve98D4Ec/+hFLliyhdevWNGvWjMzMTKZNmxazsZ25C1UoFKrehWro0KH06tWL5s2bAzB27Fg2bNjAN7/5TerXr8+gQYOAqh2qGjRoQL169ap/J1C1Rv3tt9/Oli1bSEhIYO/evdX9Xn/99bRq1QqA9PR0SkpKyM7Ojtm45cqhJRskKk7fFw9Qp06d6td16tShoqKChx56iEaNGrFixQrq1q3LF7/4xepTKaeP3b17NzfccAMLFixgzpw5nDhxgsLCQlasWMHmzZt54YUXiMdNAmfuQpWTk1O9C1WbNm3O+73Tm5Wc7XcC8PDDD3PdddexdetWCgsLOX78ePX3P/07/fTzBiIXS8EvcfHPf/6To0ePMnz4cHr27En9+vU/d8zgwYNJSEigadOmfOlLX+J///d/yc/PZ/jw4XzhC1+gSZMmDB06NA7Vn3sXqq5du/LnP/+ZAwcOUFlZydKlS+nZs+cFt/vxxx/TokUL6tSpw9NPP01lZWUURyFBpeCXuJgyZQpHjhzhH//4B++8885ZjznbDNcvkwuaOTk5vP/++3Tr1o3rrruueheqFi1a8OMf/5jevXuTlpZGKBRi+PALf5D929/+NosXL6Zr167s3buXRo0aRXEUEliRuFBwsT+6uCtvv/22JyUl+aFDh7x79+6+ZMkSX79+vQ8ePNjd3WfNmuXz5s2rPj4pKcnffvttf+ONNzwjI8OPHj3q5eXl3qFDh88cJ3IlI0IXdzXjl7hq1KgRL730Eg8//DAff/xxjcd36dKFYcOGkZaWRl5eHllZWTRt2jQGlYpcObTnrtQ6hw4donHjxhw5coQePXrw+OOPEwqF4l2WSNRpz10JrMmTJ5Oenk4oFOJb3/pWrQ/9+++/n6997Wv069ePMWPGMH/+fHr16lV9x9KBAwdITEwEoLKykunTp9OlSxdSU1P57//+7+p25s2bV/3+rFmzgKoHwjp16sS///u/k5SUxIABAzh69GjMxyiXF93HL7XOb37zm3iXEDFFRUU8++yzbN68mYqKCkKhEJmZmec8/sknn6Rp06Zs2rSJY8eO0b17dwYMGMC+ffvYt28fb7zxBu7OsGHD2LBhA23atGHfvn0sXbqUJ554glGjRrFixQrGjRsXw1HK5UbBLxJHGzduJDc3l6uuugqAYcOGnff41atXs23bNp5//nmg6vbPffv2sXr16urNaKDqdNi+ffto06YN7dq1Iz09HfjsRjMSXAp+kTg7/VDXp31645hPbxrj7vzXf/0XAwcO/Mzxf/zjH5k5cya33XbbZ94vKSn53G2xOtUjOscvEkc9evTgxRdf5OjRo5SXl/P73/8eqNpWsqioCKB6dg8wcOBAFixYwIkTJwDYu3cvhw8fZuDAgTz11FMcOnQIgPfee48PPvggxqOR2kIzfpE4CoVC3HTTTaSnp9O2bVtycnIAmDZtGqNGjeLpp5+uXv0TqraaLCkpIRQK4e40b96clStXMmDAAHbt2kW3bt2AqpVAn3nmGRISEuIyLrm86XZOkcvI7Nmzady4cUwXnZPaQ7dziojIJdGpHpHLyOzZs+NdggSAZvwiIgGj4BcRCRgFv4hIwCj4JSpKSkpITk6OdxkSZ/feey9r164962cTJkz4zDMKEju6uCsiUXPfffed9X3tLBZfmvFL1FRUVDB+/HhSU1MZMWIER44cYd26dWRkZJCSksKkSZM4duwY69atIzc3t/p7a9asIS8vL46Vy6X40Y9+RMeOHenfv3/1KqOfntUnJiZy3333kZ2dzfLly+NcbbAp+CVq9uzZw+TJk9m2bRtXX301Dz30EBMmTGDZsmVs376diooKFixYQJ8+fdi1axdlZWUALFy4kIkTJ8a5erkYhYWFrFixgs2bN/PCCy9wrgc0GzZsSH5+PqNHj45xhfJpCn6JmtatW9O9e3cAxo0bx7p162jXrh0dOnQAYPz48WzYsAEz4+abb+aZZ57ho48+oqCggBtvvDGepctFys/PZ/jw4XzhC1+gSZMmDB069KzH3XTTTTGuTM5G5/jlrO6991569OhBv379LrmNs606eS4TJ05k6NChNGzYkJEjR1K3rv6vWZtc6NIv2jz+8qAZv3xOZWUl9913X1ihD1BaWkpBQQEAS5cupV+/fpSUlPDmm28C8PTTT9OzZ08AWrZsScuWLZk7dy4TJkwIq1+JvezsbH7/+9/zySefcOjQIV5++eV4lyTnoeAPmJKSEjp27Pi5i65nXng786LcrFmzCIVCpKSksHv3bqBqs4+JEyeSkpJCamoqK1asAKo2C8nLy6NBgwaMGzeOpKQkDh48yF133cXChQsZOXIkKSkp1KlThylTplTXNnbsWFq3bk3nzp1j/4uRsHTp0oVhw4aRlpZGXl4eWVlZNG3aNN5lybm4e8x/MjMzXeLj7bffdsDz8/Pd3X3ixIk+b948b9u2rf/0pz+tPm78+PG+fPlyd3dv27atP/roo+7u/otf/MJvueUWd3e/++67/Y477qj+zsGDB72srMxzcnL80KFD7u7+k5/8xOfMmXNBtX3nO9/xX/3qV+EPUuKivLzc3d0PHz7smZmZXlRUFOeKrjxAoUcgg3UiNYDOvOj66KOPAue/8Hb69srMzExeeOEFANauXcuzzz5bfcy1117LSy+9xM6dO6vbP378ePUa8eeTmZlJo0aNePDBBy9tUBJ3kydPZufOnXzyySeMHz+eUCgU75LkHBT8AXTmRdfTr8934e309n0JCQlUVFQAVX8tntmWu9O/f3+WLl16UTWd3m1Kaq/f/OY38S5BLpDO8QfQmRdds7OzL6mdAQMG8POf/7z69YcffkjXrl35y1/+Un0B98iRI+zduzf8okUkYhT8AdSpUycWL15MamoqBw8eZOrUqZfUzn/+53/y4YcfkpycTFpaGuvXr6d58+YsWrSIMWPGkJqaSteuXasvBovI5UFbLwZMSUkJQ4YMYceOHfEuRUQukrZeFBGRSxJW8JvZPDPbbWbbzOxFM7smUoVJdCQmJmq2LxJw4c741wDJ7p4K7AVmhl+SiIhEU1jB7+6r3b3i1Mv/AVqFX5KIiERTJM/xTwL+cK4PzWyymRWaWeHp5XdFRCT2agx+M1trZjvO8jP8U8fcA1QAS87Vjrs/7u5Z7p7VvHnzyFQvInIZO9/Wk/FU45O77n7eJRrNbDwwBOjr8bg3VETkMnR6ldvLUbh39QwCZgDD3P1IZEoSEbm8xWqV227duhEKhRg5ciSHDh0CwMx+YmY7T91NOf/UeyNPnYnZamYbaqo/3HP8PweaAGvMbIuZPRZmeyIitcKZW4v+8pe/BM6/vWSzZs0oLi5m6tSpzJ8/H6jaq7hp06Zs376dbdu20adPHw4cOMDcuXNZu3YtxcXFZGVl8dBDDwEkALlA0qm7KeeeavpeYKC7pwHDaqo9rEXa3P3/hPN9EZHaKk6r3FYCnwC/MrOXgZdOfe0vwCIzew54oabatTqniMgliMcqt0899RTA9UBfYDRwO9DH3aeY2Q3AYGCLmaW7+/87Vx1askFE5BLEaZXbOkBTd18F3AmkA5jZv7r76+5+L3AAaH2+PhX8IiKXIE6r3CYAL5nZNuDPwF2nmplnZtvNbAewAdh6vj61OqeIyEWK1yq3Wp1TREQuiYJfROQi1fZVbhX8IiIBo+AXEQkYBb+ISMAo+EVEAkbBLyISMAp+EZGAUfCLiASMgl9EJGAU/CIiAaPgFxEJGAW/iEjAKPhFRAJGwS8iEjAKfhGRgFHwi4gEjIJfRCRgFPwiIgGj4BcRCRgFv4hIwCj4RUQCRsEvIhIwCn4RkYBR8IuIBIyCX0QkYBT8IiIBo+AXEQkYBb+ISMAo+EVEAiYiwW9m08zMzaxZJNoTEZHoCTv4zaw10B8oDb8cERGJtkjM+B8G7gY8Am2JiEiUhRX8ZjYMeM/dt17AsZPNrNDMCsvKysLpVkREwlC3pgPMbC3w5bN8dA/wH8CAC+nI3R8HHgfIysrSXwciInFSY/C7e7+zvW9mKUA7YKuZAbQCis3senf/R0SrFBGRiKkx+M/F3bcDXzr92sxKgCx3PxCBukREJEp0H7+ISMBc8oz/TO6eGKm2REQkejTjFxEJGAW/iEjAKPhFRAJGwS8iEjAKfhGRgFHwi4gEjIJfRCRgFPwiIgGj4BcRCRgFP/Czn/2MI0eOxLsMEZGYUPBz/uCvrKyMcTUiItEVuOA/fPgwgwcPJi0tjeTkZObMmcP+/fvp3bs3vXv3BqBx48bce++93HDDDRQUFLBu3ToyMjJISUlh0qRJHDt2DIDExERmzZpFKBQiJSWF3bt3A1BWVkb//v0JhULcdttttG3blgMHtGipiFweAhf8r7zyCi1btmTr1q3s2LGDO++8k5YtW7J+/XrWr18PVP3HITk5mddff52srCwmTJjAsmXL2L59OxUVFSxYsKC6vWbNmlFcXMzUqVOZP38+AHPmzKFPnz4UFxeTm5tLaam2IxaRy0fggj8lJYW1a9cyY8YMNm7cSNOmTT93TEJCAt/61rcA2LNnD+3ataNDhw4AjB8/ng0bNlQfm5eXB0BmZiYlJSUA5OfnM3r0aAAGDRrEtddeG80hiYhclIgty1xbdOjQgaKiIlatWsXMmTMZMODzO0c2bNiQhIQEANzPv0tkgwYNgKr/WFRUVFzQd0RE4ilwM/79+/dz1VVXMW7cOKZNm0ZxcTFNmjShvLz8rMd37NiRkpIS3nzzTQCefvppevbsed4+srOzee655wBYvXo1H374YWQHISIShsDN+Ldv38706dOpU6cO9erVY8GCBRQUFHDjjTfSokWL6vP8pzVs2JCFCxcycuRIKioq6NKlC1OmTDlvH7NmzWLMmDEsW7aMnj170qJFC5o0aRLNYYmIXDCLx2mJrKwsLywsjHm/sXLs2DESEhKoW7cuBQUFTJ06lS1btsS7LBGp5cysyN2zwm0ncDP+WCgtLWXUqFGcPHmS+vXr88QTT8S7JBGRagr+KGjfvj2bN2+OdxkiImcVuIu7IiJBp+AXEQkYBb+ISMAo+EVEAkbBLyISMAp+EZGAUfCLiASMgl9EJGAU/CIiAaPgFxEJGAW/iEjAKPhFRAJGwS8iEjBhB7+ZfdfM9pjZX83sgUgUJSIi0RPWssxm1hsYDqS6+zEz+1JkyhIRkWgJd8Y/FfiJux8DcPcPwi9JRESiKdzg7wDkmNnrZvZnM+sSiaJERCR6ajzVY2ZrgS+f5aN7Tn3/WqAr0AV4zsy+6mfZyNfMJgOTAdq0aRNOzSIiEoawNls3s1eoOtXz6qnXbwFd3b2shu+VAe9ccsfn1gw4EIV2L2caczAEccwQzHGfb8xt3b15uB2Eu+fuSqAP8KqZdQDqcwH/I0Wi8LMxs8JI7EBfm2jMwRDEMUMwxx2LMYcb/E8BT5nZDuA4MP5sp3lEROTyEVbwu/txYFyEahERkRi40p7cfTzeBcSBxhwMQRwzBHPcUR9zWBd3RUSk9rnSZvwiIlKDKzb4zWyambmZNYt3LdFmZvPMbLeZbTOzF83smnjXFC1mNujU2lBvmtkP4l1PtJlZazNbb2a7Tq2HdUe8a4oVM0sws81m9lK8a4kFM7vGzJ4/9e/yLjPrFq2+rsjgN7PWQH+gNN61xMgaINndU4G9wMw41xMVZpYA/AK4EegMjDGzzvGtKuoqgO+7eyeqHpT8TgDGfNodwK54FxFDjwCvuHtHII0ojv2KDH7gYeBuIBAXMNx9tbtXnHr5P0CreNYTRdcDb7r7307dUfYsVYsEXrHc/X13Lz71z+VUhcFX4ltV9JlZK2Aw8Kt41xILZnY10AN4EqrumHT3j6LV3xUX/GY2DHjP3bfGu5Y4mQT8Id5FRMlXgL9/6vW7BCAETzOzRCADeD2+lcTEz6iavJ2MdyEx8lWgDFh46vTWr8ysUbQ6C/cBrrioYf2g/wAGxLai6DvfmN39t6eOuYeqUwNLYllbDNlZ3gvEX3Vm1hhYAdzp7v+Mdz3RZGZDgA/cvcjMesW7nhipC4SA77r762b2CPAD4IfR6qzWcfd+Z3vfzFKAdsBWM4OqUx7FZna9u/8jhiVG3LnGfJqZjQeGAH2v4Ken3wVaf+p1K2B/nGqJGTOrR1XoL3H3F+JdTwx0B4aZ2TeAhsDVZvaMu1/JD4u+C7zr7qf/mnuequCPiiv6Pn4zKwGy3P2KXuTJzAYBDwE9a1ogrzYzs7pUXbzuC7wHbAL+zd3/GtfCosiqZjCLgYPufme864m1UzP+ae4+JN61RJuZbQRudfc9ZjYbaOTu06PRV62c8cvn/BxoAKw59ZfO/7j7lPiWFHnuXmFmtwN/BBKAp67k0D+lO3AzsN3Mtpx67z/cfVUca5Lo+C6wxMzqA38DJkaroyt6xi8iIp93xd3VIyIi56fgFxEJGAW/iEjAKPhFRAJGwS8iEjAKfhGRgFHwi4gEjIJfRCRg/j/FZGDvE1qrFQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
